## Quality and Safety for LLM Applications:
   Why Labs?

## What can go wrong?
   * Hallucinations
   * Data Leakage through prompt injection
     
   * Implicit toxicity models
   * Jail breaks

## https://www.youtube.com/watch?v=op6dmpzvYEY


